{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn\n",
    "import torch.nn.init\n",
    "import torch.utils.data as data\n",
    "# print(torch.__version__)\n",
    "# print(torchvision.__version__)\n",
    "# print(torch.cuda.is_available())\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def try_gpu():\n",
    "    \"\"\"If GPU is available, return torch.device as cuda:0; else return torch.device as cpu.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    return device\n",
    "\n",
    "device = try_gpu()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cov2D\n",
    "`torch.nn.Conv2D的输入形状是（batch_size, input_channels, height, weight）`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  二维互相关运算\n",
    "- Conv2D实际执行的是二维互相关运算。\n",
    "- 二维互相关运算的核数组左右、上下翻转才是二维卷积运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X, K):\n",
    "    \"\"\"\n",
    "    对二维特折X与核K进行卷积运算。\n",
    "    \n",
    "    :param X:二维输入特征（H,W） \n",
    "    :param K: 核数组（h,w）\n",
    "    :return: 二维输出。\n",
    "    \"\"\"\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros(X.shape[0]-h+1, X.shape[1]-w+1)\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j] = (X[i:i+h,j:j+w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "K = torch.tensor([[0, 1], [2, 3]])\n",
    "corr2d(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 无通道卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    构造二维卷积层\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size):\n",
    "        \"\"\"\n",
    "        构造二维卷积层\n",
    "        :param kernel_size: 核大小(h,w)。\n",
    "        \"\"\"\n",
    "        super(Conv2D, self).__init__()\n",
    "        self.weight = torch.nn.Parameter(torch.randn(kernel_size))\n",
    "        self.bias = torch.nn.Parameter(torch.randn(1))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        前向运算，\n",
    "        :param X: 二维输入特征（H,W）。\n",
    "        :return: 二维输出。 \n",
    "        \"\"\"\n",
    "        return corr2d(X, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积层学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c083ae4588>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = torch.ones(6, 8)\n",
    "X[:, 2:6] = 0\n",
    "plt.imshow(X.numpy(), cmap=\"gray_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = torch.tensor([[1, -1]])\n",
    "# 检测边缘算子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c083baa518>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y = corr2d(X, K)\n",
    "plt.imshow(Y.numpy(), cmap=\"gray_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5, loss 5.605\n",
      "Step 10, loss 1.502\n",
      "Step 15, loss 0.412\n",
      "Step 20, loss 0.114\n"
     ]
    }
   ],
   "source": [
    "conv2d = Conv2D(kernel_size=(1, 2))\n",
    "step, lr = 20, 0.01\n",
    "\n",
    "for i in range(step):\n",
    "    Y_hat = conv2d(X)\n",
    "    l = ((Y_hat - Y) ** 2).sum()\n",
    "    l.backward()\n",
    "\n",
    "    conv2d.weight.data -= lr * conv2d.weight.grad\n",
    "    conv2d.bias.data -= lr * conv2d.bias.grad\n",
    "\n",
    "    conv2d.weight.grad.fill_(0)\n",
    "    conv2d.bias.grad.fill_(0)\n",
    "    if (i + 1) % 5 == 0:\n",
    "        print('Step %d, loss %.3f' % (i + 1, l.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight:  tensor([[ 0.9176, -0.9113]]) tensor([[ 1, -1]])\n",
      "bias:  tensor([-0.0035])\n"
     ]
    }
   ],
   "source": [
    "print(\"weight: \", conv2d.weight.data, K)\n",
    "print(\"bias: \", conv2d.bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征图与感受野\n",
    "- 特征图：二维卷积层的输出，也是一个二维数组；\n",
    "- 感受野：影响元素x的前向计算的所有可能输入区域，堆叠Conv2D可以增大感受野。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 填充padding与步幅stride\n",
    "$${(H_Y, W_Y)} = \\lfloor(n_h-k_h+p_h+s_h)/s_h\\rfloor \\times \\lfloor(n_w-k_w+p_w+s_w)/s_w\\rfloor.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 填充\n",
    "- 填充上下左右可以用不同的填充，但一般填充的数量一样。\n",
    "- 卷积神经网络经常使用奇数高宽的卷积核，如1、3、5和7，所以两端上的填充个数相等，填充数量为$\\frac{k-1}{2}$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = torch.nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, padding=1)\n",
    "X = torch.rand(8, 8)\n",
    "X = X.view((1, 1) + X.shape)\n",
    "conv2d(X).shape[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = torch.nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(5, 3), padding=(2, 1))\n",
    "conv2d(X).shape[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步幅\n",
    "卷积窗口从输入数组的最左上方开始，按从左往右、从上往下的顺序，依次在输入数组上滑动，每次滑动的行数和列数称为步幅（stride）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = torch.nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, padding=1, stride=2)\n",
    "conv2d(X).shape[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = torch.nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(3, 5), padding=(0, 1), stride=(3,4))\n",
    "conv2d(X).shape[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多输入通道和多输出通道\n",
    "### 多输入通道\n",
    "- 当 ci=1 时，卷积核只包含一个形状为 $k_h×k_w$ 的二维数组；\n",
    "- 当 ci>1 时，每个输入通道均包含一个形状为 $k_h×k_w$ 的核数组，把这 ci 个数组在输入通道维上连结，即得到一个形状为 ci×kh×kw 的卷积核；\n",
    "- 多输入通道的输出是 ci 个互相关运算的二维输出按通道相加；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in(X, K):\n",
    "    \"\"\"\n",
    "    多输入通道的二维互相关运算。\n",
    "    :param X: 三维输入特征（in_channels, Height, Width）\n",
    "    :param K: 三维卷积数组(in_channels, height, width)\n",
    "    :return: 二维输出，与输入通道数无关。\n",
    "    \"\"\"\n",
    "    Y = corr2d(X[0,:,:], K[0,:,:])\n",
    "    for i in range(1,X.shape[0]):\n",
    "        Y += corr2d(X[i,:,:], K[i,:,:])\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 3]), torch.Size([2, 2, 2]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[[0, 1, 2], [3, 4, 5], [6, 7, 8]],\n",
    "              [[1, 2, 3], [4, 5, 6], [7, 8, 9]]])\n",
    "K = torch.tensor([[[0, 1], [2, 3]], [[1, 2], [3, 4]]])\n",
    "X.shape, K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d(X[0,:,:], K[0,:,:]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in(X, K).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多输出通道\n",
    "相当于设计了多个特征，在输出通道上连接结果，卷积核形状为$c_out×c_in×k_h×k_w$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    \"\"\"\n",
    "    多输入&输出通道的二维互相关运算。\n",
    "    \n",
    "    :param X: 三维输入特征（in_channels, Height, Width）\n",
    "    :param K: 四维卷积数组(out_channels, in_channels, height, width)\n",
    "    :return: 三维输出，与输入通道数无关(out_channels, height, width)。\n",
    "    \"\"\"\n",
    "    return torch.stack([corr2d_multi_in(X,k) for k in K],dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = torch.stack([K, K + 1, K + 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_out(X, K).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1x1卷积层\n",
    "如果将通道维当作特征维，1x1卷积层与全连接层的作用等级，保持高度与宽度不变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    \"\"\"\n",
    "    1x1卷积层等效于通道维的全连接层。\n",
    "\n",
    "    :param X: 三维输入特征（in_channels, Height, Width）\n",
    "    :param K: 四维卷积数组(out_channels, in_channels, 1, 1)\n",
    "    :return: 三维输入特征（out_channels, Height, Width）\n",
    "    \"\"\"\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.view(c_i, h * w)\n",
    "    K = K.view(c_o, c_i)\n",
    "    Y = torch.mm(K, X)  # 全连接层的矩阵乘法\n",
    "    return Y.view(c_o, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(3, 3, 3)\n",
    "K = torch.rand(2, 3, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
    "Y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y2 = corr2d_multi_in_out(X, K)\n",
    "Y2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积层的优势\n",
    "- 保存空间信息：全连接层把图像展平成一个向量，在输入图像上相邻的元素可能因为展平操作不再相邻，网络难以捕捉局部信息。而卷积层的设计，天然地具有提取局部信息的能力。\n",
    "\n",
    "- 卷积层的参数量更少：不考虑偏置的情况下，一个形状为$(c_i, c_o, h, w)$的卷积核的参数量是$c_i \\times c_o \\times h \\times w$，与输入图像的宽高无关。假如一个卷积层的输入和输出形状分别是$(c_1, h_1, w_1)$和$(c_2, h_2, w_2)$，如果要用全连接层进行连接，参数数量就是$c_1 \\times c_2 \\times h_1 \\times w_1 \\times h_2 \\times w_2$。使用卷积层可以以较少的参数数量来处理更大的图像。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 池化层\n",
    "池化层的作用是缓解卷积层对位置的过度敏感性，池化层直接计算池化窗口内元素的最大值或者平均值。\n",
    "\n",
    "- 池化层的填充、步幅与卷积层性质相同；\n",
    "- 池化层对每个通道分别池化，而不是像卷积层那样将各通道的输入按通道相加，池化层的$Channels_{in} = Channels_{out}$。\n",
    "- 池化层没有模型参数，但要参与反向传播。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `torch.nn.MaxPool2d`\n",
    "- `torch.nn.AvgPool2d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool2d(X, pool_size, mode='max'):\n",
    "    \"\"\"\n",
    "    对二维特征X进行池化操作。\n",
    "    :param X: 二维输入特征（H,W）\n",
    "    :param pool_size: 池化窗口大小(p,q)。\n",
    "    :param mode: 二维输出。\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d(X, (2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 4, 4])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(16, dtype=torch.float).view((1, 1, 4, 4))\n",
    "X = torch.cat((X, X + 1), dim=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 2, 2])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxpool2d = torch.nn.MaxPool2d(3, padding=1, stride=2)\n",
    "maxpool2d(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet\n",
    "- 卷积层保留输入形状，使图像的像素在高和宽两个方向上的相关性均可能被有效识别；\n",
    "- 卷积层通过滑动窗口将同一卷积核与不同位置的输入重复计算，从而避免参数尺寸过大。\n",
    "\n",
    "## 组成\n",
    "![LeNet网络结构](https://tangshusen.me/Dive-into-DL-PyTorch/img/chapter05/5.5_lenet.png)\n",
    "LeNet分为卷积层块和全连接层块两个部分：\n",
    "- 卷积层块里的基本单位是卷积层后接最大池化层，卷积层用来识别图像里的空间模式，如线条和物体局部，之后的最大池化层则用来降低卷积层对位置的敏感性，卷积层块由两个这样的基本单位重复堆叠构成。\n",
    "    - 卷积层使用5×5窗口，激活函数使用sigmoid，第一个卷积层输出通道数为6，第二个卷积层输出通道数则增加到16。\n",
    "    - 池化层使用2×2窗口的最大池化，步幅为2，池化窗口在输入上每次滑动所覆盖的区域互不重叠。\n",
    "    - 卷积层块的输出形状为(批量大小, 通道, 高, 宽)。\n",
    "- 全连接层块含3个全连接层，它们的输出个数分别是120、84和10，其中10为输出的类别个数。\n",
    "    - 当卷积层块的输出传入全连接层块时，全连接层块会将小批量中每个样本变平（flatten）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet：深度卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG：使用重复元素的网格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NiN：网络中的网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoogleNet：并行的网络"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
