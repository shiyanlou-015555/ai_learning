{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0+cpu\n",
      "0.5.0+cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn\n",
    "import torch.nn.init\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlp\n",
    "import rnn\n",
    "import basic\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'nlp' from 'C:\\\\Users\\\\bambo\\\\PycharmProjects\\\\ai_learning\\\\nlp.py'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器翻译及相关技术\n",
    "机器翻译的特别之处在于输入和输出都是不定长的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备\n",
    "### 读入文本\n",
    "1. 读取文本\n",
    "2. 替换法文空格为普通空格\n",
    "\n",
    "字符在计算机里是以编码的形式存在，我们通常所用的空格是 `\\x20` ，是在标准ASCII可见字符 `0x20~0x7e` 范围内。\n",
    "而 `\\xa0` 属于 `latin1 （ISO/IEC_8859-1）`中的扩展字符集字符，代表不间断空白符`nbsp(non-breaking space)`，超出`gbk`编码范围，是需要去除的特殊字符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go.\tVa !\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)\n",
      "Hi.\tSalut !\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #509819 (Aiji)\n",
      "Hi.\tSalut.\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #4320462 (gillux)\n",
      "Run!\tCours !\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906331 (sacredceltic)\n",
      "Run!\tCourez !\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906332 (sacredceltic)\n",
      "Who?\tQui ?\tCC-BY 2.0 (France) Attribution: tatoeba.org #2083030 (CK) & #4366796 (gillux)\n",
      "Wow!\tÇa alors !\tCC-BY 2.0 (France) Attribution: tatoeba.org #52027 (Zifre) & #374631 (zmoo)\n",
      "Fire!\tAu feu !\tCC-BY 2.0 (France) Attribution: tatoeba.org #1829639 (Spamster) & #4627939 (sacredceltic)\n",
      "Help!\tÀ l'aide !\tCC-BY 2.0 (France) Attribution: tatoeba.org #435084 (lukaszpp) & #128430 (sysko)\n",
      "Jump.\tSaute.\tCC-BY 2.0 (France) Attribution: tatoeba.org #631038 (Shishir) & #2416938 (Phoenix)\n",
      "Stop!\tÇa suffit !\tCC-BY 2.0 (France) Attribution: tato\n"
     ]
    }
   ],
   "source": [
    "with open(\"DataSets/fra.txt\",encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "print(raw_text[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "字典的结构是\n",
    "- 英语token\n",
    "- 法语token\n",
    "- 其他"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25666314"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_raw(text):\n",
    "    text = text.replace(\"\\u202f\",\" \").replace(\"\\xa0\",\" \")\n",
    "    out = \"\"\n",
    "    for i, char in enumerate(text.lower()):\n",
    "        if char in (\",\",\"!\",\".\") and i>0 and text[i-1]!=\" \":\n",
    "            out += \" \"\n",
    "        out += char\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go .\tva !\tcc-by 2 .0 (france) attribution: tatoeba .org #2877272 (cm) & #1158250 (wittydev)\n",
      "hi .\tsalut !\tcc-by 2 .0 (france) attribution: tatoeba .org #538123 (cm) & #509819 (aiji)\n",
      "hi .\tsalut .\tcc-by 2 .0 (france) attribution: tatoeba .org #538123 (cm) & #4320462 (gillux)\n",
      "run !\tcours !\tcc-by 2 .0 (france) attribution: tatoeba .org #906328 (papabear) & #906331 (sacredceltic)\n",
      "run !\tcourez !\tcc-by 2 .0 (france) attribution: tatoeba .org #906328 (papabear) & #906332 (sacredceltic)\n",
      "who?\tqui ?\tcc-by 2 .0 (france) attribution: tatoeba .org #2083030 (ck) & #4366796 (gillux)\n",
      "wow !\tça alors !\tcc-by 2 .0 (france) attribution: tatoeba .org #52027 (zifre) & #374631 (zmoo)\n",
      "fire !\tau feu !\tcc-by 2 .0 (france) attribution: tatoeba .org #1829639 (spamster) & #4627939 (sacredceltic)\n",
      "help !\tà l'aide !\tcc-by 2 .0 (france) attribution: tatoeba .org #435084 (lukaszpp) & #128430 (sysko)\n",
      "jump .\tsaute .\tcc-by 2 .0 (france) attribution: tatoeba .org #631038 (shishir) & #2416938 (phoenix)\n",
      "stop !\tça suffit !\tcc-b\n"
     ]
    }
   ],
   "source": [
    "# text = preprocess_raw(raw_text)\n",
    "# print(text[0:1000])\n",
    "# import pickle\n",
    "# with open(\"Datasets/fr_text.pkl\",\"wb\") as f:\n",
    "#     pickle.dump(text, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go .\tva !\tcc-by 2 .0 (france) attribution: tatoeba .org #2877272 (cm) & #1158250 (wittydev)\n",
      "hi .\tsalut !\tcc-by 2 .0 (france) attribution: tatoeba .org #538123 (cm) & #509819 (aiji)\n",
      "hi .\tsalut .\tcc-by 2 .0 (france) attribution: tatoeba .org #538123 (cm) & #4320462 (gillux)\n",
      "run !\tcours !\tcc-by 2 .0 (france) attribution: tatoeba .org #906328 (papabear) & #906331 (sacredceltic)\n",
      "run !\tcourez !\tcc-by 2 .0 (france) attribution: tatoeba .org #906328 (papabear) & #906332 (sacredceltic)\n",
      "who?\tqui ?\tcc-by 2 .0 (france) attribution: tatoeba .org #2083030 (ck) & #4366796 (gillux)\n",
      "wow !\tça alors !\tcc-by 2 .0 (france) attribution: tatoeba .org #52027 (zifre) & #374631 (zmoo)\n",
      "fire !\tau feu !\tcc-by 2 .0 (france) attribution: tatoeba .org #1829639 (spamster) & #4627939 (sacredceltic)\n",
      "help !\tà l'aide !\tcc-by 2 .0 (france) attribution: tatoeba .org #435084 (lukaszpp) & #128430 (sysko)\n",
      "jump .\tsaute .\tcc-by 2 .0 (france) attribution: tatoeba .org #631038 (shishir) & #2416938 (phoenix)\n",
      "stop !\tça suffit !\tcc-b\n"
     ]
    }
   ],
   "source": [
    "with open(\"Datasets/fr_text.pkl\",\"rb\") as f:\n",
    "    text = pickle.load(f)\n",
    "print(text[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分词\n",
    "文章字符串 -- 单词组成的（句子）的列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 50000\n",
    "source, target = [],[]\n",
    "for i, line in enumerate(text.split(\"\\n\")):\n",
    "    if i > num_examples:\n",
    "        break\n",
    "    parts = line.split(\"\\t\")\n",
    "    if len(parts) >= 2:\n",
    "        source.append(parts[0].split(\" \"))\n",
    "        target.append(parts[1].split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['go', '.'], ['hi', '.'], ['hi', '.']],\n",
       " [['va', '!'], ['salut', '!'], ['salut', '.']])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source[:3], target[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22802828668>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (6,4)\n",
    "plt.hist([[len(l) for l in source], [len(l) for l in target]], label=[\"source\", \"target\"])\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立字典\n",
    "`单词` → `id`的列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab_dict(object):\n",
    "    \"\"\"\n",
    "    建立字典的语料库，单词级别。\n",
    "    \"\"\"\n",
    "    def __init__(self, tokens, min_freq=0, use_special_tokens=False):\n",
    "        counter = collections.Counter(tokens)\n",
    "        token_freqs = sorted(counter.items(), key=lambda x:x[0])\n",
    "        token_freqs.sort(key=(lambda x:x[1]), reverse=True)\n",
    "        if use_special_tokens:\n",
    "            self.pad, self.bos, self.eos, self.unk = (0,1,2,3)\n",
    "            tokens = [\"<pad>\",\"<bos>\",\"<eos>\",\"<unk>\"]\n",
    "        else:\n",
    "            self.unk = 0\n",
    "            tokens = [\"<unk>\"]\n",
    "        tokens += [token for token, freq in token_freqs if freq >= min_freq]\n",
    "        self.idx_to_token = []\n",
    "        self.token_to_idx = dict()\n",
    "        for token in tokens:\n",
    "            self.idx_to_token.append(token)\n",
    "            self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, items):\n",
    "        if not isinstance(items, (list, tuple)):\n",
    "            return self.token_to_idx.get(items, self.unk)\n",
    "        else:\n",
    "            return [self.__getitem__(item) for item in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(tokens):\n",
    "    \"\"\"\n",
    "    从字典建立语料库。\n",
    "    :param tokens:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    tokens = [token for line in tokens for token in line]\n",
    "    return nlp.Vocab_dict(tokens, min_freq=3, use_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3789"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab = build_vocab(source)\n",
    "len(src_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 字符索引映射&长度补全"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(line, max_len, padding_token):\n",
    "    \"\"\"\n",
    "    句子截断&补全。\n",
    "    :param line: 分好词的句子。\n",
    "    :param max_len: 最大长度。\n",
    "    :param padding_token: 空白字符。\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    if len(line) > max_len:\n",
    "        return line[:max_len]\n",
    "    return line + [padding_token] * (max_len - len(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_array(lines, vocab, max_len, is_source):\n",
    "    \"\"\"\n",
    "    建立字典的每一行从token转换为idx。\n",
    "    :param lines: 字典。\n",
    "    :param vocab: 字典语料库。\n",
    "    :param max_len: 句子最大长度。\n",
    "    :param is_source: 是否标注起始、结束。\n",
    "    :return: array, valid_len\n",
    "    \"\"\"\n",
    "    lines = [vocab[line] for line in lines]\n",
    "    if not is_source:\n",
    "        lines = [[vocab.bos] + line + [vocab.eos] for line in lines]\n",
    "    array = torch.tensor([pad(line, max_len, vocab.pad) for line in lines])\n",
    "    valid_len = (array != vocab.pad).sum(dim=1)\n",
    "    return array, valid_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_nmt(source, target, batch_size, max_len): \n",
    "    \"\"\"\n",
    "    生成机器翻译字典的批量数据。\n",
    "    :param batch_size: 批量大小。\n",
    "    :param max_len: 句子长度上线。\n",
    "    :return: 迭代器\n",
    "    \"\"\"\n",
    "    src_vocab, tgt_vocab = nlp.build_vocab(source), nlp.build_vocab(target)\n",
    "    src_array, src_valid_len = nlp.build_array(source, src_vocab, max_len, True)\n",
    "    tgt_array, tgt_valid_len = nlp.build_array(target, tgt_vocab, max_len, False)\n",
    "    train_data = data.TensorDataset(src_array, src_valid_len, tgt_array, tgt_valid_len)\n",
    "    train_iter = data.DataLoader(train_data, batch_size, shuffle=True)\n",
    "    return src_vocab, tgt_vocab, train_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab, tgt_vocab, train_iter = load_data_nmt(source, target, batch_size=2, max_len=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = tensor([[ 13,  91, 980,   4,   0,   0,   0,   0],\n",
      "        [ 34, 318,  55,   7, 132,   4,   0,   0]], dtype=torch.int32) \n",
      "Valid lengths for X = tensor([4, 6]) \n",
      "Y = tensor([[   1,    5,   18,   27, 1215,    4,    2,    0],\n",
      "        [   1,   33,   88,   24,  270,   19,  141,    4]], dtype=torch.int32) \n",
      "Valid lengths for Y = tensor([7, 8])\n"
     ]
    }
   ],
   "source": [
    "for X, X_valid_len, Y, Y_valid_len, in train_iter:\n",
    "    print('X =', X.type(torch.int32), '\\nValid lengths for X =', X_valid_len,\n",
    "        '\\nY =', Y.type(torch.int32), '\\nValid lengths for Y =', Y_valid_len)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoder-decoder\n",
    "![encoder-decode结构](https://cdn.kesci.com/upload/image/q5jcat3c8m.png?imageView2/0/w/640/h/640)\n",
    "\n",
    "- encoder：输入到隐藏状态\n",
    "- decoder：隐藏状态到输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "\n",
    "    def init_state(self, enc_outputs, *args):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(torch.nn.Module):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, enc_X, dec_X, *args):\n",
    "        enc_outputs = self.encoder(enc_X, *args)\n",
    "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
    "        return self.decoder(dec_X, dec_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seq2seq\n",
    "- 预测时decoder的输暑促和是下一步的输入。\n",
    "- encoder的隐藏层状态传递给decoder。\n",
    "\n",
    "### 模型训练  \n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5jc7a53pt.png?imageView2/0/w/640/h/640)\n",
    "\n",
    "### 模型预测\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5jcecxcba.png?imageView2/0/w/640/h/640)\n",
    "\n",
    "\n",
    "\n",
    "### 具体结构：\n",
    "输入先做embedding。\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/q5jccjhkii.png?imageView2/0/w/500/h/500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder\n",
    "本编码器以LSTM（`torch.nn.LSTM`）为基础：\n",
    "- 输入X： (batch_size, seq_len, embed_size)；\n",
    "- 输出Y： (seq_len, batch_size, num_hiddens)；\n",
    "- LSTM的state： (num_layers, batch_size, num_hiddens)。\n",
    "    - 隐藏状态\n",
    "    - 记忆细胞，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqEncoder(Encoder):\n",
    "    \"\"\"\n",
    "    Encoder的具体实现。\n",
    "    X shape: (batch_size, seq_len, embed_size)；\n",
    "    Y shape: (seq_len, batch_size, num_hiddens)；\n",
    "    LSTM的state包含最后一步的隐藏状态、记忆细胞，shape是 (num_layers, batch_size, num_hiddens)。\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout=0, **kwargs):\n",
    "        super(Seq2SeqEncoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = torch.nn.LSTM(embed_size, num_hiddens, num_layers, dropout=dropout)\n",
    "\n",
    "    def begin_state(self, batch_size, device):\n",
    "        return [torch.zeros(size=(self.num_layers, batch_size, self.num_hiddens), device=device),\n",
    "                torch.zeros(size=(self.num_layers, batch_size, self.num_hiddens), device=device)]\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        X = self.embedding(X)  # X shape: (batch_size, seq_len, embed_size)\n",
    "        X = X.transpose(0, 1)  # RNN needs first axes to be time\n",
    "        # state = self.begin_state(X.shape[1], device=X.device)\n",
    "        out, state = self.rnn(X)\n",
    "        return out, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7, 4, 16]), 2, torch.Size([2, 4, 16]), torch.Size([2, 4, 16]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Seq2SeqEncoder(vocab_size=10, embed_size=8,num_hiddens=16, num_layers=2)\n",
    "X = torch.zeros((4, 7),dtype=torch.long)\n",
    "output, state = encoder(X)\n",
    "output.shape, len(state), state[0].shape, state[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDecoder(Decoder):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout=0, **kwargs):\n",
    "        super(Seq2SeqDecoder, self).__init__(**kwargs)\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = torch.nn.LSTM(embed_size,num_hiddens, num_layers, dropout=dropout)\n",
    "        self.dense = torch.nn.Linear(num_hiddens,vocab_size)\n",
    "\n",
    "    def init_state(self, enc_outputs, *args):\n",
    "        return enc_outputs[1]\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        X = self.embedding(X).transpose(0, 1)\n",
    "        out, state = self.rnn(X, state)\n",
    "        # Make the batch to be the first dimension to simplify loss computation.\n",
    "        out = self.dense(out).transpose(0, 1)\n",
    "        return out, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 7, 10]), 2, torch.Size([2, 4, 16]), torch.Size([2, 4, 16]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Seq2SeqDecoder(vocab_size=10, embed_size=8,num_hiddens=16, num_layers=2)\n",
    "state = decoder.init_state(encoder(X))\n",
    "out, state = decoder(X, state)\n",
    "out.shape, len(state), state[0].shape, state[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数\n",
    "仅在有效长度求损失"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 有效长度掩码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SequenceMask(X, X_len,value=0):\n",
    "    \"\"\"\n",
    "    对于不定长序列求损失函数，仅在有效长度进行。\n",
    "    :param X: (batch_size, maxlen)每一行是一个序列数据。\n",
    "    :param X_len: (batch_size,)有效长度。\n",
    "    :param value: mask。\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    maxlen = X.size(1)\n",
    "    mask = torch.arange(maxlen)[None, :].to(X_len.device) < X_len[:, None]   \n",
    "    X[~mask]=value\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [4, 5, 0]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[1,2,3], [4,5,6]])\n",
    "SequenceMask(X,torch.tensor([1,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 带掩码的损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedSoftmaxCELoss(torch.nn.CrossEntropyLoss):\n",
    "    \"\"\"\n",
    "    带掩码的交叉熵损失函数类。\n",
    "    \n",
    "    X shape: (batch_size, seq_len, vocab_size)\n",
    "    y shape: (batch_size, seq_len)\n",
    "    valid_length shape: (batch_size, )\n",
    "    \"\"\"\n",
    "    def forward(self, pred, label, valid_length):\n",
    "        # the sample weights shape should be (batch_size, seq_len)\n",
    "        weights = torch.ones_like(label)\n",
    "        weights = SequenceMask(weights, valid_length).float()\n",
    "        self.reduction='none'\n",
    "        # (batch_size, vocab_size, seq_len) x (batch_size, seq_len) -> (batch_size, seq_len)\n",
    "        output=super(MaskedSoftmaxCELoss, self).forward(pred.transpose(1,2), label)\n",
    "        return (output*weights).mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3026, 1.7269, 0.0000])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = MaskedSoftmaxCELoss()\n",
    "loss(torch.ones((3, 4, 10)), torch.ones((3,4),dtype=torch.long), torch.tensor([4,3,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_clipping_nn(model, theta, device):\n",
    "    grad_clipping(model.parameters(), theta, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ch7(model, data_iter, lr, num_epochs, device):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss = MaskedSoftmaxCELoss()\n",
    "    tic = time.time()\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        l_sum, num_tokens_sum = 0.0, 0.0\n",
    "        for batch in data_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X, X_vlen, Y, Y_vlen = [x.to(device) for x in batch]\n",
    "            Y_input, Y_label, Y_vlen = Y[:, :-1], Y[:, 1:], Y_vlen - 1\n",
    "            Y_hat, _ = model(X, Y_input, X_vlen, Y_vlen)\n",
    "            \n",
    "            l = loss(Y_hat, Y_label, Y_vlen).sum()\n",
    "            l.backward()\n",
    "            with torch.no_grad():\n",
    "                rnn.grad_clipping(model.parameters(), 5, device)\n",
    "            num_tokens = Y_vlen.sum().item()\n",
    "            optimizer.step()\n",
    "            \n",
    "            l_sum += l.sum().item()\n",
    "            num_tokens_sum += num_tokens\n",
    "        if epoch % 50 == 0:\n",
    "            print(\"epoch {0:4d},loss {1:.3f}, time {2:.1f} sec\".format(\n",
    "                epoch, (l_sum / num_tokens_sum), time.time() - tic))\n",
    "            tic = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.0\n",
    "batch_size, num_examples, max_len = 64, 1e3, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs, ctx = 0.005, 300, basic.try_gpu()\n",
    "src_vocab, tgt_vocab, train_iter = data.load_data_nmt(source, target, batch_size, max_len)\n",
    "encoder = Seq2SeqEncoder(len(src_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
    "decoder = Seq2SeqDecoder(len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
    "model = EncoderDecoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-59a7f7bdc971>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_ch7\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-63-cb7888eb33b9>\u001b[0m in \u001b[0;36mtrain_ch7\u001b[1;34m(model, data_iter, lr, num_epochs, device)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_vlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                 \u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_clipping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_ch7(model, train_iter, lr, num_epochs, ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_ch7(model, src_sentence, src_vocab, tgt_vocab, max_len, device):\n",
    "    \"\"\"\n",
    "    机器翻译的enc-dec预测。\n",
    "    :param model: encoder-decode模型。\n",
    "    :param src_sentence: 待翻译语句。\n",
    "    :param src_vocab: 源语言词典。\n",
    "    :param tgt_vocab: 目标语言词典。\n",
    "    :param max_len: 最大有效句子长度。\n",
    "    :param device: CPU/GPU。\n",
    "    :return: 翻译好的语句。\n",
    "    \"\"\"\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')]\n",
    "    src_len = len(src_tokens)\n",
    "    if src_len < max_len:\n",
    "        src_tokens += [src_vocab.pad] * (max_len - src_len)\n",
    "    enc_X = torch.tensor(src_tokens, device=device)\n",
    "    enc_valid_length = torch.tensor([src_len], device=device)\n",
    "    enc_outputs = model.encoder(enc_X.unsqueeze(dim=0), enc_valid_length)\n",
    "    dec_state = model.decoder.init_state(enc_outputs, enc_valid_length)\n",
    "    dec_X = torch.tensor([tgt_vocab.bos], device=device).unsqueeze(dim=0)\n",
    "    predict_tokens = []\n",
    "    for _ in range(max_len):\n",
    "        Y, dec_state = model.decoder(dec_X, dec_state)\n",
    "        # The token with highest score is used as the next time step input.\n",
    "        dec_X = Y.argmax(dim=2)\n",
    "        py = dec_X.squeeze(dim=0).int().item()\n",
    "        if py == tgt_vocab.eos:\n",
    "            break\n",
    "        predict_tokens.append(py)\n",
    "    return ' '.join(tgt_vocab.to_tokens(predict_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 集束搜索\n",
    "贪心搜搜，挑选较好的几个继续预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 注意力机制及Seq2Seq模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "279.273px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
